---
title: "OSHA Data Clean-Up -- MA 415 Midterm"
author: "William Dean"
output: 
  pdf_document:
    toc: true
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
require(foreign)
require(dplyr)
require(tidyr)
require(ggplot2)
require(ggmap)
require(lubridate)
require(zipcode)

### READ IN ALL THE FILES ###
a <- read.dbf("accid.DBF")
A <- read.dbf("lookups/acc.dbf")
O <- read.dbf("lookups/occ.DBF")
H <- read.dbf("lookups/hzs.dbf")

o <- read.dbf("osha.DBF")
N <- read.dbf("lookups/naics.dbf")
Si <- read.dbf("lookups/sic.dbf")

data("zipcode")
```

# Objective 

The OSHA data presents Health & Safety Regulations and all workplace injuries and accidents. This data is ready and available, however it is very messy and is not able to be interpreted easily.  The goal of this project is to clean this OSHA dataframes given with the intent of looking for the most dangerous place to work in the state of Massachusetts and provide insite of the data through Data Exploration.


# Problems with the OSHA Data -- OSHA Clean-Up

## Accident Table

The Accident Table from OSHA is a record of the accidents and the situation behind each accident. There is a lot of information as can be seen in the display of it below but it needs to be cleaned up to before exploring it and anything more.

```{r echo=FALSE }
kable(head(a,3),format="markdown")
```

### Unnecessary Atributes

At first glance, the dataframe that represents the accidents in MA is very messy and has many attributes that would not be helpful to looking into the most dangerous places to work in Massachusetts, so these were the first to be eliminated.
A Person's name or the RELINSP (An inpections key) doesn't give much use to look at dangerous locations and are taken out to simplify the data.

```{r echo=FALSE}
### CLEAN a, Accident DATAFRAME ###
a <- select(a, -c(NAME,RELINSP, SITESTATE))
kable(head(a, 3),format="markdown")
```

### Getting Rid of Incorrect Information (NA Values)

Although this is better, there is much information that is stored as placeholder values when they should be NA. For example, an OCC_CODE of "000" does not refer to an Occupation and should be NA. Taking out all instances of bad values cleans the data more.

```{r echo=FALSE}
a$AGE[a$AGE == 0] <- NA
a$OCC_CODE[a$OCC_CODE == "000"] <- NA
a$HAZSUB[a$HAZSUB == "0000"] <- NA
a$TASK[a$TASK == "0"] <- NA
a$DEGREE[a$DEGREE == "0"] <- NA
kable(head(a, 3),format="markdown")
```

### Give Appropriate Labels

There is a lot of information in the table that is not stored in this table but in other tables that would be better suited to have all in one location. Bringing this information to one table makes it easier to understand what the data means and will make exploration and analysis easier.
The resulting table is much cleaner and can be seen below.

```{r echo=FALSE, message=FALSE, include=FALSE}
levels(a$DEGREE) <- c(NA, "Fatal", "Hospitalized", "Non-Hospitalized")
levels(a$TASK) <- c(NA, "Regular", "Irregular")

names(O)[1] <- "OCC_CODE" # Prep for left join
a <- left_join(a, O, by = "OCC_CODE") 
a <- select(a, -c(OCC_CODE))
names(H)[1] <- "HAZSUB" # Prep for left join
a <- left_join(a, H, by = "HAZSUB")
a <- select(a, -c(HAZSUB))
names(a)[ncol(a)] <- "HAZSUB"

Hum <- filter(A, CATEGORY == "HUMAN-FAC")
names(Hum)[2] <- "HUMAN"
Hum <- select(Hum, -c(CATEGORY))
a <- left_join(a, Hum, by = "HUMAN")
a <- select(a, -c(HUMAN))
names(a)[ncol(a)] <- "HUMFACT"

Bod <- filter(A, CATEGORY == "PART-BODY")
names(Bod)[2] <- "BODYPART"
Bod <- select(Bod, -c(CATEGORY))
a <- left_join(a, Bod, by = "BODYPART")
a <- select(a, -c(BODYPART))
names(a)[ncol(a)] <- "BODYPART"

Nat <- filter(A, CATEGORY == "NATUR-INJ")
names(Nat)[2] <- "NATURE"
Nat <- select(Nat, -c(CATEGORY))
a <- left_join(a, Nat, by = "NATURE")
a <- select(a, -c(NATURE))
names(a)[ncol(a)] <- "NATURE"

Source <- filter(A, CATEGORY == "SOURC-INJ")
names(Source)[2] <- "SOURCE"
Source <- select(Source, -c(CATEGORY))
a <- left_join(a, Source, by = "SOURCE")
a <- select(a, -c(SOURCE))
names(a)[ncol(a)] <- "SOURCE"

Envir <- filter(A, CATEGORY == "ENVIR-FAC")
names(Envir)[2] <- "ENVIRON"
Envir <- select(Envir, -c(CATEGORY))
a <- left_join(a, Envir, by = "ENVIRON")
a <- select(a, -c(ENVIRON))
names(a)[ncol(a)] <- "ENVIRON"

Event <- filter(A, CATEGORY == "EVENT-TYP")
names(Event)[2] <- "EVENT"
Event <- select(Event, -c(CATEGORY))
a <- left_join(a, Event, by = "EVENT")
a <- select(a, -c(EVENT))
names(a)[ncol(a)] <- "EVENT"
```
```{r echo=FALSE}
kable(head(a, 3),format="markdown")
```

###Final Version

This provides much a much cleaner version of the original accident table but there exists rows which have the same values everywhere that are redundant.
Taking them out givens a final version of the table we started with.

```{r echo=FALSE}
a <- distinct(a)
kable(head(a, 3),format="markdown")
```

## OSHA Table

The OSHA Table contains the information for all of the Inpections that have happened which is able to give us more information about the accidents in Massachusetts. Our goal is to combine the important information from the OSHA table to the Accident table we have already made to how a condensed table with all the accident information. However, we run into a lot of the same problems as the Accident table so the OSHA table has to be cleaned and preped before joining. The given OSHA table is too large and messy and can be seen below:

```{r echo=FALSE}
kable(head(o[,1:13],3),format="markdown")
```

### Cleaning the Table

After taking only the information we want, getting rid of incorrect values which should be NAs, and relabeling the keys stored as integers with more discriptive and accurate labels, we come of with a version of the OSHA table that will provide important information about what happened at each inspection.
A final version of the OSHA table before combining with the Accident table can be seen below and is easier to understand the information compared to how it was originally presented.

```{r echo=FALSE,include=FALSE}
o <- select(o, c(ACTIVITYNO,ESTABNAME,SITEADD, OWNERTYPE,OPENDATE, CLOSEDATE,NAICS,SIC,SITEZIP))
levels(o$OWNERTYPE) <- c("Private", "Local Gov't", "State Gov't", "Fed Gov't")
o$OPENDATE[o$OPENDATE == 0] <- NA
o$CLOSEDATE[o$CLOSEDATE == 0] <- NA
o$OPENDATE <- ymd(o$OPENDATE)
o$CLOSEDATE <- ymd(o$CLOSEDATE)
o$NAICS[o$NAICS == "000000"] <- NA
o$SITEZIP[o$SITEZIP == "00000"] <- NA
o <- left_join(o, N, by="NAICS")
o <- select(o, -c(NAICS))
o <- left_join(o, Si, by="SIC")
o <- select(o, -c(SIC))
# zipcode
zipcode <- filter(zipcode, state =="MA")
zipcode <- select(zipcode, -c(state))
names(zipcode)[1] <- "SITEZIP"
o <- left_join(o, zipcode, by="SITEZIP")
o <- select(o, -c(SITEZIP))
o <- distinct(o)
o <- mutate(o, Decade= year(OPENDATE) %% 100) # Group by Decade
o <- mutate(o, Decade=Decade - (Decade %% 10))
o$Decade <- as.factor(o$Decade)
levels(o$Decade) <- c("00s","70s", "80s", "90s")
o$Decade <- factor(o$Decade, levels = c("70s", "80s", "90s", "00s"))
```
```{r echo=FALSE} 
kable(head(o,3),format="markdown")
```

## Complete Accidents Table
We have two tables with information about the accidents in MA, but now we want to store it all in one table. Using a left join, we can keep all the information about the accidents from the accident table, but we can also incorporate any additional information that the OSHA table will give about each accident.
Joining the tables results in one single table that has all the information from the data frames which would be helpful in exploring the most dangerous places in Massachusetts.

```{r echo=FALSE} 
Accidents <- left_join(a, o, by = "ACTIVITYNO")
# Any Last minute fixes
Accidents$ESTABNAME[Accidents$ESTABNAME == "BOSTON EDISON CO"] <- "BOSTON EDISON COMPANY"
Accidents$OCCUPATION[Accidents$OCCUPATION == "CONSTRUCTION TRADES, N.E.C."] <- "CONSTRUCTION LABORERS"
Accidents <- distinct(Accidents)
kable(head(Accidents,5),format="markdown")
```

# Exploring the Data

Now that we have a Table with all the useful information about all the accidents that happened and have it organized, we can begin to explore the accidents in Massachusetts. Because of the our tidy data which brings in many types of attributes for each accidents, we can produce many visualizations from the data. Here are a few types:

```{r echo=FALSE,include=FALSE}
### GET Map of MA ###
map <- get_map(location='massachusetts', zoom=8)
m <- ggmap(map)
```

## Bar Graphs

Since there are so many discrete variables, we can explore them with the use of bar graphs. Let's first consider the 10 most frequent __Occupations__ in our data:

```{r echo=FALSE,fig.width=10}
Occ <- filter(Accidents, Accidents$OCCUPATION != "OCCUPATION NOT REPORTED")
Occ <- Occ[ Occ$OCCUPATION %in%  names(tail(sort(table(Occ$OCCUPATION)),10)), ]
f <- ggplot(Occ, aes(OCCUPATION, fill = OCCUPATION))
f + geom_bar() + theme(axis.text.x=element_text(angle=90,hjust=.5,vjust=0.5)) +
  ggtitle("Top 10 Most Accident-Prone Occupations in MA")
```

The plot above gives incite to which occupations lead to the most amount of injuries, but it does not tell us the severity of those injuries.

Because of that, consider the same set of data, but grouped by another variable, __Degree__ of Accidents. Here we can consider the outcome of the 10 most frequent Occupations in the data:

```{r echo=FALSE,fig.width=10}
f + geom_bar() +  
  facet_wrap(~DEGREE) + coord_flip() +
  ggtitle("Results from Top 10 Most Accident-Prone Occupations in MA")
```

We are able to consider if the most accident-prone jobs tend to have serious injuries or just many none serious injuries.  


## Time Series -- Time Occurances

Using the Accident's Date, we can explore when and how many accidents happen. Consider still the Top 10 Accident-Prone Occupations. We can see when theses accidents happened:

```{r echo=FALSE, fig.width=10}
ggplot(data=Occ, aes(OPENDATE, color=OCCUPATION)) + geom_density(alpha=.25, size = 1.5) +
  ggtitle("Occurences of Top 10 Occupations -- 1980s to 2005")
```

Many of these results skew either left or right, so it may be considered if these are disappearing career paths or rising, more dangerous careers. Perhaps the job are changing.

Let's now explore another Attribute over time, Company names.

Sub-setting by the 10 Most Occuring Companies, we can see when in time these Accident-Prone companies had these Accidents:

```{r echo=FALSE,fig.width=10}
Comp <- Accidents[Accidents$ESTABNAME %in% names(tail(sort(table(Accidents$ESTABNAME)),10)),]
ggplot(data=Comp,aes(OPENDATE,color=ESTABNAME)) + geom_density(size = 1.5) + facet_wrap(~ESTABNAME,scales="free_y") +
  ggtitle("Time Occurances of Accidents by Top 10 Most Accident-Prone Companies")
```

All of these companies had many accidents but the time over which they had these accidents differ and can be visualized with the plots. Some have smaller accidents throughout time while some have large accidents that occur not so often.

## Histograms

Histograms can be used to see the distributions of some of our discrete variables. Consider the accidents that occur per city in the whole time frame:

```{r echo=FALSE,fig.width=10} 
City <- as.data.frame(table(Accidents$city))
ggplot(City,aes(Freq)) + geom_histogram(bins=45) + ggtitle("Distribution of Number of Accidents per City")
```

Over a time interval, we are able to see that lower amounts of accidents are more likely to occur. Cities with more accidents are less frequent and could be accounted by being larger, more industrial places.

## Map Graphics

With the use of location, we can visualize where in the state these accidents occured. We are able to see where the cities with the most accidents are. 

```{r echo=FALSE, fig.width=10}
City <- Accidents[Accidents$city %in% names(tail(sort(table(Accidents$city)),10)),]
m + geom_point(data=City, aes(longitude, latitude, color = city), size = 4) +
  ggtitle("Location of Cities with Top 10 Most Accidents")
```

We can see that many of these location are near Boston, but also near cities where there is a lot of industry compared to smaller places.

Another option is to see where in Massachusetts had the most accidents throughout time. To make it easier to see, let's group accidents by the decade in which they occured. We can see whether accidents are moving to new locations throughout the state.

```{r echo=FALSE, fig.width=10}
m + geom_point(data=Accidents,aes(longitude,latitude,color=Decade),na.rm=T, size =3) + ggtitle("Location of Accidents over the Decades")
```

There could be a trend that is moving accidents toward Boston.

# Final Remarks

By cleaning up the data but also bringing in the most information we can about each accident, we get one data frame that is easy to understand and ready to explore.  At the beginning, our data of interest was scattered across many tables and had many values that were incorrect but, by using R, we are able to bring the data to one place.

The data is versatile in the many ways it can be visually explored. The ways to explore the data that are above are just a subset of all possible. The data can be see through many of the dicrete variables, the frequency of them, the time occurance of accidents, and/or geographical locations of accidents.  

The data that was prepared can be taken in many directions to discover the most dangerous place to work, and to uncover the multifaceted stories behind each.
